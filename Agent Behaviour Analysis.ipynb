{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from pid import PIDModel\n",
    "from agent import Agent, Actor, Critic, Transition\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading up Actor and Critic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_SIZE = 500\n",
    "SET_POINT = 1000\n",
    "\n",
    "t = np.linspace(0, 50, num=T_SIZE)\n",
    "SP = np.ones(T_SIZE)*SET_POINT\n",
    "\n",
    "env = PIDModel(ku=1.396, tu=3.28, t=t, SP=SP)\n",
    "\n",
    "actor = Actor()\n",
    "critic = Critic()\n",
    "agent = Agent(env,\n",
    "    actor_lr=0, critic_lr=0,\n",
    "    actor_model=actor, critic_model=critic,\n",
    "    device=args[\"DEVICE\"], gamma=0.95)\n",
    "\n",
    "\n",
    "print(agent.get_action(torch.Tensor([0.5, 0.5, 3, 10, 10])))\n",
    "agent.load()\n",
    "print(agent.get_action(torch.Tensor([0.5, 0.5, 50, 0, 1000])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emulating some episodes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "done = False\n",
    "total = 0\n",
    "\n",
    "agent.start_episode()\n",
    "state, init_reward, __ = env.step((0.5, 0.5, 3.5))  # Initial random state\n",
    "num_step = 0\n",
    "rewards = [init_reward]\n",
    "states = [state]\n",
    "while not done:\n",
    "    action = agent.get_action(state)\n",
    "\n",
    "    new_state, reward, done = env.step(action)\n",
    "    transition = Transition(\n",
    "        reward=reward, state=state,\n",
    "        action=action, target_action=action,\n",
    "        next_state=new_state)\n",
    "    agent.step(transition)\n",
    "\n",
    "    total += reward\n",
    "    state = new_state\n",
    "    num_step += 1\n",
    "    rewards.append(reward)\n",
    "    states.append(state)\n",
    "\n",
    "y_caps = np.array(env.output())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = y_caps[:, 0]\n",
    "\n",
    "plt.plot(SP, label=\"Set Point\")\n",
    "plt.plot(response, label=\"Response\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Response\")\n",
    "plt.savefig('trained_response.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rewards)\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.savefig(\"trained_reward.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = SP-response\n",
    "plt.plot(error)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.savefig(\"trained_error.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_error = -y_caps[:, 1]\n",
    "plt.plot(d_error)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Derivative of error\")\n",
    "plt.savefig(\"trained_de_t.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max overshoot\n",
    "error_pd = -pd.Series(error)\n",
    "\n",
    "# Max overshoot is when |error| is maximum after touching the set point first, i.e after first crossing zero\n",
    "first_cross = error_pd[((error_pd.shift() <= 0) & (error_pd >= 0))].index[0]\n",
    "\n",
    "print(\"Max overshoot: \", error_pd[first_cross: ].abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settling time: first occurence of when tolerance band is reached\n",
    "# tolerance band is +-TOLERANCE_BAND percent of the target set point\n",
    "\n",
    "TOLERANCE_BAND = 5/100 # Within 5% of the target is tolerable\n",
    "abs_tolerance = TOLERANCE_BAND*SP[0]\n",
    "\n",
    "settling_time = t[error_pd[(error_pd.abs() < abs_tolerance)].index[0]]\n",
    "print(\"Settling time (5%): \", settling_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settling time: first occurence of when tolerance band is reached\n",
    "# tolerance band is +-TOLERANCE_BAND percent of the target set point\n",
    "\n",
    "TOLERANCE_BAND = 2/100 # Within 5% of the target is tolerable\n",
    "abs_tolerance = TOLERANCE_BAND*SP[0]\n",
    "\n",
    "settling_time = t[error_pd[(error_pd.abs() < abs_tolerance)].index[0]]\n",
    "print(\"Settling time (2%): \", settling_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
